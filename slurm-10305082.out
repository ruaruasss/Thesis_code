Start Deterministic Training with seed 99
Namespace(device='cuda:0', data='/home/p_tf_zy/p_tf_01/TESTAM-main/data/METR-LA', adjdata='/home/p_tf_zy/p_tf_01/TESTAM-main/data/METR-LA/adj_mx.pkl', adjtype='doubletransition', out_dim=1, nhid=32, in_dim=2, num_nodes=207, batch_size=64, dropout=0.3, epochs=100, print_every=50, seed=99, save='/home/p_tf_zy/p_tf_01/TESTAM-main/experiment/METR-LA_TESTAM', expid=1, load_path=None, patience=15, lr_mul=1, n_warmup_steps=4000, quantile=0.7, is_quantile=False, warmup_epoch=0)
正在加载邻接矩阵文件: /home/p_tf_zy/p_tf_01/TESTAM-main/data/METR-LA/adj_mx.pkl
文件加载成功，数据内容: [['773869', '767541', '767542', '717447', '717446', '717445', '773062', '767620', '737529', '717816', '765604', '767471', '716339', '773906', '765273', '716331', '771667', '716337', '769953', '769402', '769403', '769819', '769405', '716941', '717578', '716960', '717804', '767572', '767573', '773012', '773013', '764424', '769388', '716328', '717819', '769941', '760987', '718204', '718045', '769418', '768066', '772140', '773927', '760024', '774012', '774011', '767609', '769359', '760650', '716956', '769831', '761604', '717495', '716554', '773953', '767470', '716955', '764949', '773954', '767366', '769444', '773939', '774067', '769443', '767750', '767751', '767610', '773880', '764766', '717497', '717490', '717491', '717492', '717493', '765176', '717498', '717499', '765171', '718064', '718066', '765164', '769431', '769430', '717610', '767053', '767621', '772596', '772597', '767350', '767351', '716571', '773023', '767585', '773024', '717483', '718379', '717481', '717480', '717486', '764120', '772151', '718371', '717489', '717488', '717818', '718076', '718072', '767455', '767454', '761599', '717099', '773916', '716968', '769467', '717576', '717573', '717572', '717571', '717570', '764760', '718089', '769847', '717608', '767523', '716942', '718090', '769867', '717472', '717473', '759591', '764781', '765099', '762329', '716953', '716951', '767509', '765182', '769358', '772513', '716958', '718496', '769346', '773904', '718499', '764853', '761003', '717502', '759602', '717504', '763995', '717508', '765265', '773996', '773995', '717469', '717468', '764106', '717465', '764794', '717466', '717461', '717460', '717463', '717462', '769345', '716943', '772669', '717582', '717583', '717580', '716949', '717587', '772178', '717585', '716939', '768469', '764101', '767554', '773975', '773974', '717510', '717513', '717825', '767495', '767494', '717821', '717823', '717458', '717459', '769926', '764858', '717450', '717452', '717453', '759772', '717456', '771673', '772167', '769372', '774204', '769806', '717590', '717592', '717595', '772168', '718141', '769373'], {'717099': 110, '773869': 0, '767541': 1, '767542': 2, '717447': 3, '717446': 4, '717445': 5, '773062': 6, '767053': 84, '737529': 8, '717816': 9, '765604': 10, '767471': 11, '716339': 12, '772596': 86, '765273': 14, '716331': 15, '771667': 16, '716337': 17, '769953': 18, '769402': 19, '769403': 20, '769819': 21, '769405': 22, '769345': 164, '716960': 25, '717804': 26, '767572': 27, '767573': 28, '773012': 29, '773013': 30, '764424': 31, '764101': 176, '769388': 32, '716328': 33, '717819': 34, '769941': 35, '760987': 36, '718204': 37, '718045': 38, '769418': 39, '768066': 40, '772140': 41, '773927': 42, '769867': 126, '772513': 138, '774012': 44, '774011': 45, '767609': 46, '760650': 48, '765099': 131, '769831': 50, '772669': 166, '767585': 92, '716554': 53, '773953': 54, '767470': 55, '762329': 132, '764949': 57, '773954': 58, '767366': 59, '769444': 60, '773939': 61, '774067': 62, '769443': 63, '767750': 64, '767751': 65, '767610': 66, '773880': 67, '764766': 68, '717497': 69, '717490': 70, '717491': 71, '717492': 72, '717493': 73, '765176': 74, '717498': 75, '717499': 76, '765171': 77, '718064': 78, '718066': 79, '718371': 101, '769431': 81, '769430': 82, '717489': 102, '767620': 7, '767621': 85, '773906': 13, '772597': 87, '767350': 88, '767351': 89, '716571': 90, '773023': 91, '761604': 51, '773024': 93, '717483': 94, '718379': 95, '717481': 96, '717480': 97, '717486': 98, '764120': 99, '772151': 100, '765164': 80, '717610': 83, '717488': 103, '769806': 200, '717818': 104, '718076': 105, '718072': 106, '767455': 107, '767454': 108, '769847': 121, '761599': 109, '717495': 52, '773916': 111, '716968': 112, '769467': 113, '717576': 114, '717573': 115, '717572': 116, '717571': 117, '717570': 118, '764760': 119, '718089': 120, '717578': 24, '717608': 122, '759602': 147, '760024': 43, '717472': 127, '717473': 128, '759591': 129, '764781': 130, '716956': 49, '716955': 56, '716953': 133, '716951': 134, '767509': 135, '769358': 137, '769359': 47, '716958': 139, '718496': 140, '769346': 141, '773904': 142, '718499': 143, '764853': 144, '761003': 145, '717502': 146, '718090': 125, '717504': 148, '763995': 149, '717508': 150, '771673': 196, '773996': 152, '773995': 153, '717469': 154, '717468': 155, '764106': 156, '717465': 157, '764794': 158, '717466': 159, '717461': 160, '717460': 161, '717463': 162, '717462': 163, '716941': 23, '716943': 165, '716942': 124, '717582': 167, '717583': 168, '717580': 169, '716949': 170, '717587': 171, '772178': 172, '717585': 173, '716939': 174, '768469': 175, '765182': 136, '767554': 177, '773975': 178, '773974': 179, '717510': 180, '717513': 181, '717825': 182, '767495': 183, '767494': 184, '717821': 185, '717823': 186, '717458': 187, '717459': 188, '769926': 189, '764858': 190, '717450': 191, '717452': 192, '717453': 193, '759772': 194, '717456': 195, '765265': 151, '772167': 197, '718141': 205, '774204': 199, '767523': 123, '717590': 201, '717592': 202, '717595': 203, '772168': 204, '769372': 198, '769373': 206}, array([[1.       , 0.       , 0.       , ..., 0.       , 0.       ,
        0.       ],
       [0.       , 1.       , 0.3909554, ..., 0.       , 0.       ,
        0.       ],
       [0.       , 0.7174379, 1.       , ..., 0.       , 0.       ,
        0.       ],
       ...,
       [0.       , 0.       , 0.       , ..., 1.       , 0.       ,
        0.       ],
       [0.       , 0.       , 0.       , ..., 0.       , 1.       ,
        0.       ],
       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,
        1.       ]], dtype=float32)]
邻接矩阵加载成功。
初始化的邻接矩阵(前5行5列):
 tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.3910, 0.0000, 0.0000],
        [0.0000, 0.7174, 1.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.6337],
        [0.0000, 0.0000, 0.0000, 0.6265, 1.0000]], device='cuda:0')
Train the model with 208507 parameters
start training...
Iter: 000, Train Loss: 16.9633, Train MAPE: 0.3537, Train RMSE: 18.6144
Iter: 050, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 100, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 150, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 200, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 250, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 300, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 350, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Epoch: 001, Inference Time: 4.6466 secs
Epoch: 001, Train Loss: nan, Train MAPE: 0.0037, Train RMSE: 0.1977, Valid Loss: 0.0000, Valid MAPE: 0.0000, Valid RMSE: 0.0000, Training Time: 104.0767/epoch
Iter: 000, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 050, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 100, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 150, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 200, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 250, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 300, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 350, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Epoch: 002, Inference Time: 4.6558 secs
Epoch: 002, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000, Valid Loss: 0.0000, Valid MAPE: 0.0000, Valid RMSE: 0.0000, Training Time: 101.6635/epoch
Iter: 000, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 050, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 100, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 150, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 200, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 250, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 300, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 350, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Epoch: 003, Inference Time: 4.6571 secs
Epoch: 003, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000, Valid Loss: 0.0000, Valid MAPE: 0.0000, Valid RMSE: 0.0000, Training Time: 101.6864/epoch
Iter: 000, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 050, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 100, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 150, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 200, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 250, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 300, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 350, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Epoch: 004, Inference Time: 4.6581 secs
Epoch: 004, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000, Valid Loss: 0.0000, Valid MAPE: 0.0000, Valid RMSE: 0.0000, Training Time: 101.7192/epoch
Iter: 000, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 050, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 100, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 150, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 200, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 250, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 300, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 350, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Epoch: 005, Inference Time: 4.7936 secs
Epoch: 005, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000, Valid Loss: 0.0000, Valid MAPE: 0.0000, Valid RMSE: 0.0000, Training Time: 104.9604/epoch
Iter: 000, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 050, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 100, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 150, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 200, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 250, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 300, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 350, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Epoch: 006, Inference Time: 4.6522 secs
Epoch: 006, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000, Valid Loss: 0.0000, Valid MAPE: 0.0000, Valid RMSE: 0.0000, Training Time: 101.6992/epoch
Iter: 000, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
Iter: 050, Train Loss: nan, Train MAPE: 0.0000, Train RMSE: 0.0000
slurmstepd: error: *** JOB 10305082 ON x1001c3s1b0n1 CANCELLED AT 2025-03-15T16:11:26 ***
